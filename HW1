import numpy as np
import pandas as pd
from sklearn.model_selection import KFold, ParameterGrid
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping
import tensorflow as tf

# 1. Load or create synthetic data
np.random.seed(42)
df = pd.DataFrame({
    'ball_diameter': np.random.uniform(10, 50, 200),
    'rolling_force': np.random.uniform(100, 500, 200),
    'initial_roughness': np.random.uniform(0.1, 2.0, 200),
    'num_passes': np.random.randint(1, 10, 200),
    'surface_hardness': np.random.uniform(200, 400, 200),
    'final_roughness': np.random.uniform(0.05, 1.0, 200)
})

# 2. EDA (brief)
print(df.describe())
print(df.corr())

# 3. Data preparation
X = df[['ball_diameter', 'rolling_force', 'initial_roughness', 'num_passes']].values
y_hardness = df['surface_hardness'].values
y_roughness = df['final_roughness'].values
y_joint = df[['surface_hardness', 'final_roughness']].values

scaler_X = StandardScaler()
X_scaled = scaler_X.fit_transform(X)

# 4. Keras model builder
def build_keras_model(n_hidden=1, n_neurons=10, activation='relu', dropout_rate=0.2, optimizer='adam', output_dim=1):
    model = keras.Sequential()
    model.add(layers.Input(shape=(X.shape[1],)))
    for _ in range(n_hidden):
        model.add(layers.Dense(n_neurons, activation=activation))
        model.add(layers.Dropout(dropout_rate))
    model.add(layers.Dense(output_dim))
    model.compile(loss='mse', optimizer=optimizer, run_eagerly=True)
    return model

# 5. Hyperparameter grid
param_grid = {
    'n_hidden': [1, 2, 3],
    'n_neurons': [5, 10, 15],
    'activation': ['sigmoid', 'relu', 'tanh'],
    'dropout_rate': [0.2, 0.3, 0.4],
    'optimizer': ['sgd', 'rmsprop', 'adam']
}

# 6. Early stopping callback
early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# 7. K-Fold setup
kfold = KFold(n_splits=10, shuffle=True, random_state=42)

# ✅ No longer decorated — allows .fit() without symbolic errors
def train_model(model, X_train, y_train):
    model.fit(X_train, y_train, epochs=100, batch_size=16,
              validation_split=0.1, callbacks=[early_stop], verbose=0)
    return model

# 8. Grid search and cross-validation for single output
def grid_search_cv_single(X, y, output_dim=1):
    best_score = np.inf
    best_params = None
    best_model = None
    all_results = []
    for params in ParameterGrid(param_grid):
        mse_scores = []
        r2_scores = []
        for train_idx, test_idx in kfold.split(X):
            X_train, X_test = X[train_idx], X[test_idx]
            y_train, y_test = y[train_idx], y[test_idx]
            model = build_keras_model(**params, output_dim=output_dim)
            y_train = np.reshape(y_train, (-1, output_dim))
            y_test = np.reshape(y_test, (-1, output_dim))
            train_model(model, X_train, y_train)
            y_pred = model.predict(X_test).flatten() if output_dim == 1 else model.predict(X_test)
            mse_scores.append(mean_squared_error(y_test, y_pred))
            r2_scores.append(r2_score(y_test, y_pred))
        avg_mse = np.mean(mse_scores)
        avg_r2 = np.mean(r2_scores)
        all_results.append((params, avg_mse, avg_r2))
        if avg_mse < best_score:
            best_score = avg_mse
            best_params = params
            best_model = build_keras_model(**params, output_dim=output_dim)
            train_model(best_model, X, np.reshape(y, (-1, output_dim)))
    return best_params, best_score, best_model, all_results

# 9. Grid search and cross-validation for joint output
def grid_search_cv_joint(X, y):
    best_score = np.inf
    best_params = None
    best_model = None
    all_results = []
    for params in ParameterGrid(param_grid):
        mse_scores = []
        r2_scores = []
        for train_idx, test_idx in kfold.split(X):
            X_train, X_test = X[train_idx], X[test_idx]
            y_train, y_test = y[train_idx], y[test_idx]
            model = build_keras_model(**params, output_dim=2)
            y_train = np.reshape(y_train, (-1, 2))
            y_test = np.reshape(y_test, (-1, 2))
            train_model(model, X_train, y_train)
            y_pred = model.predict(X_test)
            mse_scores.append(mean_squared_error(y_test, y_pred, multioutput='raw_values'))
            r2_scores.append(r2_score(y_test, y_pred, multioutput='raw_values'))
        avg_mse = np.mean(mse_scores, axis=0)
        avg_r2 = np.mean(r2_scores, axis=0)
        all_results.append((params, avg_mse, avg_r2))
        if np.mean(avg_mse) < best_score:
            best_score = np.mean(avg_mse)
            best_params = params
            best_model = build_keras_model(**params, output_dim=2)
            train_model(best_model, X, np.reshape(y, (-1, 2)))
    return best_params, best_score, best_model, all_results

# 10. Run grid search and evaluation
print("Grid search for surface hardness...")
params_hardness, mse_hardness, model_hardness, results_hardness = grid_search_cv_single(X_scaled, y_hardness, output_dim=1)
print("Grid search for final roughness...")
params_roughness, mse_roughness, model_roughness, results_roughness = grid_search_cv_single(X_scaled, y_roughness, output_dim=1)
print("Grid search for joint model...")
params_joint, mse_joint, model_joint, results_joint = grid_search_cv_joint(X_scaled, y_joint)

# 11. Final evaluation on all data (for reporting)
y_pred_hardness = model_hardness.predict(X_scaled).flatten()
y_pred_roughness = model_roughness.predict(X_scaled).flatten()
y_pred_joint = model_joint.predict(X_scaled)

print("\nBest hyperparameters for surface hardness:", params_hardness)
print("Best hyperparameters for final roughness:", params_roughness)
print("Best hyperparameters for joint model:", params_joint)

print(f"\nSurface Hardness - MSE: {mean_squared_error(y_hardness, y_pred_hardness):.3f}, R2: {r2_score(y_hardness, y_pred_hardness):.3f}")
print(f"Final Roughness - MSE: {mean_squared_error(y_roughness, y_pred_roughness):.3f}, R2: {r2_score(y_roughness, y_pred_roughness):.3f}")
print(f"Joint Model - MSE: {mean_squared_error(y_joint, y_pred_joint, multioutput='raw_values')}, R2: {r2_score(y_joint, y_pred_joint, multioutput='raw_values')}")

# 12. Conclusion
print("Both separate and joint Keras models were trained and evaluated using grid search and 10-fold cross-validation.\n"
      "The best hyperparameters were selected based on the lowest mean squared error (MSE).\n"
      "The joint model allows for simultaneous prediction of both outputs, which may be beneficial if the outputs are correlated.\n"
      "If the joint model's performance (MSE and R2) is comparable to or better than the separate models, it is preferable due to its simplicity and efficiency.\n"
      "Otherwise, separate models may be used for higher accuracy on individual outputs.")