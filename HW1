import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import KFold, ParameterGrid
from sklearn.preprocessing  import StandardScaler
from sklearn.metrics        import mean_squared_error, r2_score
import keras
from keras import layers
from keras.callbacks import EarlyStopping
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)

# Load & synthesize data
np.random.seed(42)
df = pd.DataFrame({
    'ball_diameter':     np.random.uniform(10, 50, 200),
    'rolling_force':     np.random.uniform(100, 500, 200),
    'initial_roughness': np.random.uniform(0.1, 2.0, 200),
    'num_passes':        np.random.randint(1, 10, 200),
    'surface_hardness':  np.random.uniform(200, 400, 200),
    'final_roughness':   np.random.uniform(0.05, 1.0, 200)
})

# Exploratory Data Analysis
print("\n=== DESCRIPTIVE STATISTICS ===")
print(df.describe().to_string())

print("\n=== CORRELATION MATRIX ===")
corr = df.corr()
plt.figure(figsize=(6,5))
sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm", vmin=-1, vmax=1)
plt.title("Feature Correlations")
plt.tight_layout()
plt.show()

# Scaling (Standardization)
print("\nScaling method: StandardScaler (zero mean, unit variance).")
features = ['ball_diameter','rolling_force','initial_roughness','num_passes']
X = df[features].values
y_h = df['surface_hardness'].values
y_r = df['final_roughness'].values
y_j = df[['surface_hardness','final_roughness']].values

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Build Keras model
def build_model(n_hidden, n_neurons, activation, dropout_rate, optimizer, output_dim):
    m = keras.Sequential()
    m.add(layers.Input(shape=(X_scaled.shape[1],)))
    for _ in range(n_hidden):
        m.add(layers.Dense(n_neurons, activation=activation))
        m.add(layers.Dropout(dropout_rate))
    m.add(layers.Dense(output_dim))
    m.compile(loss='mse', optimizer=optimizer)
    return m

# Hyperparameter grid
param_grid = {
    'n_hidden':     [1, 2, 3],
    'n_neurons':    [5, 10, 15],
    'activation':   ['sigmoid','relu','tanh'],
    'dropout_rate': [0.2, 0.3, 0.4],
    'optimizer':    ['sgd','rmsprop','adam']
}

# Callbacks
# For CV: monitor training loss only (no inner validation_split)
early_stop_cv = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)
# For final re-fit: monitor val_loss so you get val curves
early_stop_final = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# 10‐Fold Cross‐Validation
kfold = KFold(n_splits=10, shuffle=True, random_state=42)

def run_grid_cv(X, y, output_dim):
    records = []
    for params in ParameterGrid(param_grid):
        mse_scores, r2_scores = [], []
        for train_idx, test_idx in kfold.split(X):
            X_tr, X_te = X[train_idx], X[test_idx]
            y_tr, y_te = y[train_idx], y[test_idx]
            y_tr2 = y_tr.reshape(-1, output_dim)
            y_te2 = y_te.reshape(-1, output_dim)

            model = build_model(**params, output_dim=output_dim)
            model.fit(
                X_tr, y_tr2,
                epochs=100, batch_size=16,
                callbacks=[early_stop_cv],
                verbose=0
            )

            y_pred = model.predict(X_te)
            if output_dim == 1:
                y_pred = y_pred.flatten()
                y_te2 = y_te2.flatten()

            mse_scores.append(mean_squared_error(y_te2, y_pred))
            r2_scores.append(r2_score(y_te2, y_pred))

        records.append({
            **params,
            'avg_mse': np.mean(mse_scores),
            'std_mse': np.std(mse_scores),
            'avg_r2':  np.mean(r2_scores),
            'std_r2':  np.std(r2_scores)
        })

    return pd.DataFrame(records)

# Run Grid‐Search for each target
print("\nRunning CV grid‐search for surface hardness...")
df_h = run_grid_cv(X_scaled, y_h, output_dim=1)

print("Running CV grid‐search for final roughness...")
df_r = run_grid_cv(X_scaled, y_r, output_dim=1)

print("Running CV grid‐search for joint model...")
df_j = run_grid_cv(X_scaled, y_j, output_dim=2)

# Display Top‐10 Results
for name, df_res in [('Hardness', df_h), ('Roughness', df_r), ('Joint', df_j)]:
    print(f"\n=== Top 10 hyperparameter sets for {name} by avg_mse ===")
    print(df_res.sort_values('avg_mse').head(10).to_string(index=False))

# Sample Justification Plot
plt.figure(figsize=(8,5))
sns.scatterplot(
    data=df_h,
    x='n_neurons', y='avg_mse',
    hue='n_hidden',
    palette='viridis', s=80, alpha=0.7
)
plt.title("Surface Hardness: avg_mse vs n_neurons (hue=n_hidden)")
plt.tight_layout()
plt.show()

# Refit Best Models on Full Data
best_h = df_h.loc[df_h['avg_mse'].idxmin()].to_dict()
best_r = df_r.loc[df_r['avg_mse'].idxmin()].to_dict()
best_j = df_j.loc[df_j['avg_mse'].idxmin()].to_dict()

for d in (best_h, best_r, best_j):
    for key in ('avg_mse','std_mse','avg_r2','std_r2'):
        d.pop(key, None)

print("\nBest hyperparameters found:")
print(" • Hardness :", best_h)
print(" • Roughness:", best_r)
print(" • Joint    :", best_j)

def train_final(X, y, params, output_dim):
    model = build_model(**params, output_dim=output_dim)
    history = model.fit(
        X, y.reshape(-1, output_dim),
        validation_split=0.1,
        epochs=200, batch_size=16,
        callbacks=[early_stop_final],
        verbose=0
    )
    return model, history

model_h, hist_h = train_final(X_scaled, y_h, best_h, 1)
model_r, hist_r = train_final(X_scaled, y_r, best_r, 1)
model_j, hist_j = train_final(X_scaled, y_j, best_j, 2)

# Plot Final Train/Val Loss
for title, hist in [('Hardness', hist_h),
                    ('Roughness', hist_r),
                    ('Joint', hist_j)]:
    plt.figure(figsize=(6,4))
    plt.plot(hist.history['loss'],  label='train')
    plt.plot(hist.history['val_loss'],label='val')
    plt.title(f"{title} Model Loss")
    plt.xlabel("Epoch"); plt.ylabel("MSE Loss")
    plt.legend(); plt.grid(True); plt.tight_layout()
    plt.show()

# Final Performance on All Data

yhat_h = model_h.predict(X_scaled).flatten()
yhat_r = model_r.predict(X_scaled).flatten()
yhat_j = model_j.predict(X_scaled)

print("\nFINAL Performance on FULL DATA:")
print(f" • Hardness   MSE={mean_squared_error(y_h, yhat_h):.3f}, "
      f"R²={r2_score(y_h, yhat_h):.3f}")
print(f" • Roughness  MSE={mean_squared_error(y_r, yhat_r):.3f}, "
      f"R²={r2_score(y_r, yhat_r):.3f}")

mse_j, r2_j = (
    mean_squared_error(y_j, yhat_j, multioutput='raw_values'),
    r2_score(y_j, yhat_j, multioutput='raw_values')
)
print(f" • Joint      MSE=[{mse_j[0]:.3f}, {mse_j[1]:.3f}], "
      f"R²=[{r2_j[0]:.3f}, {r2_j[1]:.3f}]")