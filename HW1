import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
# Enable eager execution everywhere:
tf.config.run_functions_eagerly(True)
tf.data.experimental.enable_debug_mode()

from sklearn.model_selection import KFold, ParameterGrid
from sklearn.preprocessing  import StandardScaler
from sklearn.metrics        import mean_squared_error, r2_score

from keras import layers, initializers, Sequential
from keras.optimizers import SGD, RMSprop, Adam
from keras.callbacks    import EarlyStopping

# === 1. SYNTHESIZE & INSPECT DATA ===
np.random.seed(42)
df = pd.DataFrame({
    'ball_diameter':     np.random.uniform(10, 50, 200),
    'rolling_force':     np.random.uniform(100, 500, 200),
    'initial_roughness': np.random.uniform(0.1, 2.0, 200),
    'num_passes':        np.random.randint(1, 10, 200),
    'surface_hardness':  np.random.uniform(200, 400, 200),
    'final_roughness':   np.random.uniform(0.05, 1.0, 200)
})
print("Dataset shape:", df.shape)
display(df.head())

# EDA
print("\nDescriptive statistics:")
display(df.describe())
plt.figure(figsize=(6,5))
sns.heatmap(df.corr(), annot=True, fmt=".2f",
            cmap="coolwarm", vmin=-1, vmax=1)
plt.title("Feature Correlations")
plt.tight_layout()
plt.show()

# === 2. SCALE FEATURES ===
features = ['ball_diameter','rolling_force','initial_roughness','num_passes']
X = df[features].values
y_h = df['surface_hardness'].values
y_r = df['final_roughness'].values
y_j = df[['surface_hardness','final_roughness']].values

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print("Standardized inputs: means ~", np.round(X_scaled.mean(0),3),
      " stds ~", np.round(X_scaled.std(0),3))

# === 3. GRID & CV SETUP ===
param_grid = {
    'n_hidden':     [1, 2, 3],
    'n_neurons':    [5, 10, 15],
    'activation':   ['sigmoid','relu','tanh'],
    'dropout_rate': [0.2, 0.3, 0.4],
    'optimizer':    ['sgd','rmsprop','adam']
}
kfold = KFold(n_splits=10, shuffle=True, random_state=42)
early_stop_cv    = EarlyStopping(monitor='loss',     patience=10, restore_best_weights=True)
early_stop_final = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Instead of reusing optimizer objects, store factory functions:
optimizer_factories = {
    'sgd':     lambda: SGD(learning_rate=1e-3, clipnorm=1.0),
    'rmsprop': lambda: RMSprop(learning_rate=1e-3),
    'adam':    lambda: Adam(learning_rate=1e-3)
}

# === 4. MODEL BUILDER ===
def build_model(n_hidden, n_neurons, activation, dropout_rate, optimizer, output_dim):
    m = Sequential()
    m.add(layers.Input(shape=(X_scaled.shape[1],)))
    for _ in range(n_hidden):
        m.add(layers.Dense(
            n_neurons,
            activation=activation,
            kernel_initializer=initializers.HeNormal()
        ))
        m.add(layers.Dropout(dropout_rate))
    m.add(layers.Dense(output_dim))
    m.compile(
        loss='mse',
        optimizer=optimizer_factories[optimizer](),
        run_eagerly=True
    )
    return m

# === 5. GRID-SEARCH with NaN SKIP ===
def run_grid_cv(X, y, output_dim):
    records = []
    combos = list(ParameterGrid(param_grid))
    total = len(combos)
    for idx, params in enumerate(combos, start=1):
        print(f"[{idx}/{total}] Params: {params}")
        mse_fold, r2_fold = [], []
        for train_ix, val_ix in kfold.split(X):
            Xtr, Xte = X[train_ix], X[val_ix]
            ytr = y[train_ix].reshape(-1, output_dim)
            yte = y[val_ix].reshape(-1, output_dim)

            m = build_model(**params, output_dim=output_dim)
            m.fit(
                Xtr, ytr,
                epochs=100, batch_size=16,
                validation_split=0.1,
                callbacks=[early_stop_cv],
                verbose=0
            )

            ypred = m.predict(Xte)
            if output_dim == 1:
                ypred = ypred.flatten()
                yte   = yte.flatten()

            if np.isnan(ypred).any():
                print("   → NaN preds; skipping fold")
                continue

            mse_fold.append(mean_squared_error(yte, ypred))
            r2_fold.append(r2_score(yte, ypred))

        if mse_fold:
            records.append({
                **params,
                'avg_mse': np.mean(mse_fold),
                'std_mse': np.std(mse_fold),
                'avg_r2':  np.mean(r2_fold),
                'std_r2':  np.std(r2_fold)
            })
    return pd.DataFrame(records)

# === 6. RUN CV FOR HARDNESS, ROUGHNESS, JOINT ===
print("\n>> Surface hardness CV")
df_h = run_grid_cv(X_scaled, y_h, output_dim=1)

print("\n>> Final roughness CV")
df_r = run_grid_cv(X_scaled, y_r, output_dim=1)

print("\n>> Joint model CV")
df_j = run_grid_cv(X_scaled, y_j, output_dim=2)

# === 7. DISPLAY TOP-10 ===
for label, df_res in [('Hardness',df_h), ('Roughness',df_r), ('Joint',df_j)]:
    print(f"\n--- Top 10 for {label} by avg_mse ---")
    display(df_res.sort_values('avg_mse').head(10))

# === 8. REFIT BEST AND PLOT TRAIN/VAL LOSS ===
def train_final(X, y, params, output_dim):
    m = build_model(**params, output_dim=output_dim)
    history = m.fit(
        X, y.reshape(-1,output_dim),
        validation_split=0.1,
        epochs=200, batch_size=16,
        callbacks=[early_stop_final],
        verbose=0
    )
    return m, history

# Extract and clean best param dicts:
best_h = df_h.loc[df_h['avg_mse'].idxmin()].drop(['avg_mse','std_mse','avg_r2','std_r2']).to_dict()
best_r = df_r.loc[df_r['avg_mse'].idxmin()].drop(['avg_mse','std_mse','avg_r2','std_r2']).to_dict()
best_j = df_j.loc[df_j['avg_mse'].idxmin()].drop(['avg_mse','std_mse','avg_r2','std_r2']).to_dict()
print("Best (hardness):", best_h)
print("Best (roughness):", best_r)
print("Best (joint):", best_j)

model_h, hist_h = train_final(X_scaled, y_h, best_h, 1)
model_r, hist_r = train_final(X_scaled, y_r, best_r, 1)
model_j, hist_j = train_final(X_scaled, y_j, best_j, 2)

for title, hist in [('Hardness',hist_h), ('Roughness',hist_r), ('Joint',hist_j)]:
    plt.figure(figsize=(6,4))
    plt.plot(hist.history['loss'],  label='train')
    plt.plot(hist.history['val_loss'],label='val')
    plt.title(f"{title}: Train vs. Val Loss")
    plt.xlabel("Epoch"); plt.ylabel("MSE")
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

# === 9. FINAL METRICS ON FULL DATA ===
yhat_h = model_h.predict(X_scaled).flatten()
yhat_r = model_r.predict(X_scaled).flatten()
yhat_j = model_j.predict(X_scaled)

print("\nFinal Performance:")
print(f" Hardness:  MSE={mean_squared_error(y_h,yhat_h):.3f}, R²={r2_score(y_h,yhat_h):.3f}")
print(f" Roughness: MSE={mean_squared_error(y_r,yhat_r):.3f}, R²={r2_score(y_r,yhat_r):.3f}")
mse_j, r2_j = (
    mean_squared_error(y_j, yhat_j, multioutput='raw_values'),
    r2_score(y_j, yhat_j, multioutput='raw_values')
)
print(f" Joint:     MSE=[{mse_j[0]:.3f},{mse_j[1]:.3f}], "
      f"R²=[{r2_j[0]:.3f},{r2_j[1]:.3f}]")