import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import KFold, ParameterGrid
from sklearn.preprocessing  import StandardScaler
from sklearn.metrics        import mean_squared_error, r2_score
import keras
from keras import layers
from keras.callbacks import EarlyStopping
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)

# Data
np.random.seed(42)
df = pd.DataFrame({
    'ball_diameter':      np.random.uniform(10, 50, 200),
    'rolling_force':      np.random.uniform(100, 500, 200),
    'initial_roughness':  np.random.uniform(0.1, 2.0, 200),
    'num_passes':         np.random.randint(1, 10, 200),
    'surface_hardness':   np.random.uniform(200, 400, 200),
    'final_roughness':    np.random.uniform(0.05, 1.0, 200)
})

# Exploratory Data Analysis
print("\n=== DESCRIPTIVE STATISTICS ===")
print(df.describe().to_string())
print("\n=== CORRELATION MATRIX ===")
corr = df.corr()
plt.figure(figsize=(6,5))
sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm", vmin=-1, vmax=1)
plt.title("Feature Correlations")
plt.tight_layout()
plt.show()

# Scaling method (Standardization) 
print("\nScaling method: StandardScaler (zero mean, unit variance).")
X = df[['ball_diameter','rolling_force','initial_roughness','num_passes']].values
y_h = df['surface_hardness'].values
y_r = df['final_roughness'].values
y_j = df[['surface_hardness','final_roughness']].values
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Model builder
def build_model(n_hidden, n_neurons, activation, dropout_rate, optimizer, output_dim):
    model = keras.Sequential()
    model.add(layers.Input(shape=(X_scaled.shape[1],)))
    for _ in range(n_hidden):
        model.add(layers.Dense(n_neurons, activation=activation))
        model.add(layers.Dropout(dropout_rate))
    model.add(layers.Dense(output_dim))
    model.compile(loss='mse', optimizer=optimizer)
    return model

# Hyperparameter grid
param_grid = {
    'n_hidden':     [1, 2, 3],
    'n_neurons':    [5, 10, 15],
    'activation':   ['sigmoid','relu','tanh'],
    'dropout_rate': [0.2, 0.3, 0.4],
    'optimizer':    ['sgd','rmsprop','adam']
}

early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Cross‐validation
kfold = KFold(n_splits=10, shuffle=True, random_state=42)

def run_grid_cv(X, y, output_dim):
    records = []
    for params in ParameterGrid(param_grid):
        mse_folds = []
        r2_folds  = []
        for train_idx, test_idx in kfold.split(X):
            X_tr, X_te = X[train_idx], X[test_idx]
            y_tr, y_te = y[train_idx], y[test_idx]
            y_tr2 = y_tr.reshape(-1, output_dim)
            y_te2 = y_te.reshape(-1, output_dim)

            model = build_model(**params, output_dim=output_dim)
            model.fit(
                X_tr, y_tr2,
                validation_split=0.1,
                epochs=100, batch_size=16,
                callbacks=[early_stop],
                verbose=0
            )

            y_pred = model.predict(X_te)
            if output_dim == 1:
                y_pred = y_pred.flatten()
                y_te2 = y_te2.flatten()

            mse_folds.append(mean_squared_error(y_te2, y_pred))
            r2_folds.append(r2_score(y_te2, y_pred))

        records.append({
            **params,
            'avg_mse': np.mean(mse_folds),
            'std_mse': np.std(mse_folds),
            'avg_r2':  np.mean(r2_folds),
            'std_r2':  np.std(r2_folds)
        })

    return pd.DataFrame(records)


# Grid Search
print("\nRunning CV grid‐search for surface hardness...")
df_h = run_grid_cv(X_scaled, y_h, output_dim=1)

print("Running CV grid‐search for final roughness...")
df_r = run_grid_cv(X_scaled, y_r, output_dim=1)

print("Running CV grid‐search for joint model...")
df_j = run_grid_cv(X_scaled, y_j, output_dim=2)

# Top 10 hyperparameter sets
for name, df_res in [('Hardness', df_h), ('Roughness', df_r), ('Joint', df_j)]:
    print(f"\n=== Top 10 hyperparameter sets for {name} (by avg_mse) ===")
    print(df_res.sort_values('avg_mse').head(10).to_string(index=False))

# Sample hyperparameter‐performance plot
plt.figure(figsize=(8,5))
sns.scatterplot(
    data=df_h,
    x='n_neurons', y='avg_mse',
    hue='n_hidden', palette='viridis',
    s=80, alpha=0.7
)
plt.title("Surface hardness: avg_mse vs n_neurons (hue=n_hidden)")
plt.tight_layout()
plt.show()

# Refit best models
best_h = df_h.loc[df_h['avg_mse'].idxmin()].to_dict()
best_r = df_r.loc[df_r['avg_mse'].idxmin()].to_dict()
best_j = df_j.loc[df_j['avg_mse'].idxmin()].to_dict()

for d in (best_h, best_r, best_j):
    for k in ('avg_mse','std_mse','avg_r2','std_r2'):
        d.pop(k, None)

print("\nBest params (hardness):", best_h)
print("Best params (roughness):", best_r)
print("Best params (joint):", best_j)

def train_final(X, y, params, output_dim):
    model = build_model(**params, output_dim=output_dim)
    history = model.fit(
        X, y.reshape(-1, output_dim),
        validation_split=0.1,
        epochs=200, batch_size=16,
        callbacks=[early_stop],
        verbose=0
    )
    return model, history

model_h, hist_h = train_final(X_scaled, y_h, best_h, 1)
model_r, hist_r = train_final(X_scaled, y_r, best_r, 1)
model_j, hist_j = train_final(X_scaled, y_j, best_j, 2)

# Plot training & validation loss curves
for title, hist in [('Hardness', hist_h),
                    ('Roughness', hist_r),
                    ('Joint', hist_j)]:
    plt.figure(figsize=(6,4))
    plt.plot(hist.history['loss'],  label='train')
    plt.plot(hist.history['val_loss'],label='val')
    plt.title(f'{title} Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('MSE Loss')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Evaluation
yhat_h = model_h.predict(X_scaled).flatten()
yhat_r = model_r.predict(X_scaled).flatten()
yhat_j = model_j.predict(X_scaled)

print("\nFINAL Performance on FULL DATA:")
print(f"Hardness   MSE={mean_squared_error(y_h, yhat_h):.3f}, R²={r2_score(y_h, yhat_h):.3f}")
print(f"Roughness  MSE={mean_squared_error(y_r, yhat_r):.3f}, R²={r2_score(y_r, yhat_r):.3f}")

mse_j, r2_j = mean_squared_error(y_j, yhat_j, multioutput='raw_values'), \
             r2_score(y_j, yhat_j, multioutput='raw_values')
print(f"Joint      MSE=[{mse_j[0]:.3f}, {mse_j[1]:.3f}], "
      f"R²=[{r2_j[0]:.3f}, {r2_j[1]:.3f}]") 